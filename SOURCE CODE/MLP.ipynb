{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPt9gwWZkZRglYnxvqnM6Rd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VI8hkq31NztA"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","def imshow(img):\n","    img = img * torch.tensor([0.247, 0.243, 0.261]).view(3, 1, 1) + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n","    np_img = img.numpy()\n","    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n","    plt.show()\n","\n","for i, (images, labels) in enumerate(trainloader, 0):\n","    print(f\"Labels: {[classes[labels[j]] for j in range(8)]}\")\n","    imshow(torchvision.utils.make_grid(images[:8]))\n","    break\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32 * 32 * 3, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 10)\n","        )\n","        for m in self.model:\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","model = MLP().to(device)\n","print(model)\n","\n","input_tensor = torch.rand(5, 3, 32, 32).to(device)\n","output = model(input_tensor)\n","print(f\"Output shape: {output.shape}\")\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True)\n","\n","def evaluate(model, testloader, criterion):\n","    model.eval()\n","    test_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for images, labels in testloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    accuracy = 100 * correct / total\n","    test_loss = test_loss / len(testloader)\n","    return test_loss, accuracy, all_preds, all_labels\n","\n","test_loss, test_accuracy, _, _ = evaluate(model, testloader, criterion)\n","print(f\"Initial Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n","\n","train_losses = []\n","train_accuracies = []\n","test_losses = []\n","test_accuracies = []\n","max_epoch = 100\n","patience = 20\n","best_test_acc = 0\n","patience_counter = 0\n","\n","for epoch in range(max_epoch):\n","    model.train()\n","    running_loss = 0.0\n","    running_correct = 0\n","    total = 0\n","    for i, (inputs, labels) in enumerate(trainloader, 0):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        running_correct += (predicted == labels).sum().item()\n","        loss.backward()\n","        optimizer.step()\n","    epoch_accuracy = 100 * running_correct / total\n","    epoch_loss = running_loss / (i + 1)\n","    test_loss, test_accuracy, preds, labels = evaluate(model, testloader, criterion)\n","    print(f\"Epoch [{epoch + 1}/{max_epoch}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n","\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_accuracy)\n","    test_losses.append(test_loss)\n","    test_accuracies.append(test_accuracy)\n","\n","    scheduler.step(test_accuracy)\n","\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        patience_counter = 0\n","        torch.save(model.state_dict(), 'best_model.pth')\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch + 1}\")\n","            break\n","\n","model.load_state_dict(torch.load('best_model.pth'))\n","test_loss, test_accuracy, preds, labels = evaluate(model, testloader, criterion)\n","print(f\"Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%\")\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(test_losses, label='Test Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_accuracies, label='Train Accuracy')\n","plt.plot(test_accuracies, label='Test Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","plt.show()\n","\n","cm = confusion_matrix(labels, preds)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()"]}]}